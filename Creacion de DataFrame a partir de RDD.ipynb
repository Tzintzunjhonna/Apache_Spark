{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import IntegerType, StringType, FloatType\n",
    "from pyspark.sql.types import Row\n",
    "\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkContext(master='local', appName=\"TransformacionesYAcciones\")\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/contreras/Descargas/Spark/files/'\n",
    "deportistaOlimpicoRDD = spark.textFile(path+'deportista.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "\n",
    "deportistaOlimpicoRDD2 = spark.textFile(path+'deportista2.csv') \\\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "\n",
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.union(deportistaOlimpicoRDD2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retiramos encabezado\n",
    "\n",
    "def eliminarEncabezado(indice, iterador):\n",
    "    return iter(list(iterador)[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.\\\n",
    "    mapPartitionsWithIndex(eliminarEncabezado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD = deportistaOlimpicoRDD.map(lambda l: (\n",
    "    int(1[0]),\n",
    "    l[1],\n",
    "    int(l[2]),\n",
    "    int(l[3]),\n",
    "    float(l[5]),\n",
    "    int(l[6]),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Schema = StructType([\n",
    "    StructField('deportista_id', IntegerType(), False),\n",
    "    StructField('nombre', StringType(), False),\n",
    "    StructField('genero', IntegerType(), False),\n",
    "    StructField('edad', IntegerType(), False),\n",
    "    StructField('altura', IntegerType(), False),\n",
    "    StructField('peso', FloatType(), False),\n",
    "    StructField('edad', IntegerType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaDF = sqlContext.createDataFrame(deportistaOlimpico, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RETO CREAR LOS DATA FRAME RESTANTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paises Equipos\n",
    "\n",
    "equiposilimpicosRDD = spark.textFile(path+'paises.csv')\\\n",
    "    .map(lambda line: line.split(\",\"))\\\n",
    "    .mapPartitionsWithindex(eliminarEncabezado) \\\n",
    "    .map(lambda l : (\n",
    "    \n",
    "    int(l[0]),\n",
    "    l[1],\n",
    "    l[2],\n",
    "))\n",
    "\n",
    "equiposSchema = StructType([\n",
    "    StructField('id', IntegerType(), False),\n",
    "    StructField('equipo', StringType(), False),\n",
    "    StructFiel('sigla', StringType(), False),\n",
    "])\n",
    "\n",
    "paisesDf = sqlContext.createDataFrame(equiposolimpicosRDD, equiposSchema)\n",
    "\n",
    "paisesDF.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deportes\n",
    "\n",
    "Schema = Structype([\n",
    "    StructFiel('deporte_id', Integertype(), False),\n",
    "    StructField('deporte', StringType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "# Paso 2 Crea DATAFRAME con la lectura del Schema\n",
    "\n",
    "deportesDF = sqlContext.read.schema(deporteSchema) \\\n",
    "    .option('header', 'true').csv(path+'deporte.csv')\n",
    "\n",
    "deportesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evento\n",
    "\n",
    "Schema = Structype([\n",
    "    StructFiel('evento_id', Integertype(), False),\n",
    "    StructField('nombre', StringType(), False),\n",
    "    StructFiel('deporte_id', Integertype(), False),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Paso 2 Crea DATAFRAME con la lectura del Schema\n",
    "\n",
    "deportesOlimpicosDF = sqlContext.read.schema(eventoSchema) \\\n",
    "    .option('header', 'true').csv(path+'evento.csv')\n",
    "\n",
    "ddeportesOlimpicosDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPERACIONES SOBRE DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ver el Schema\n",
    "deportesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENOMBRADO DE COLUMNAS\n",
    "\n",
    "deportistaOlimpicoDF = deportistaDF \\\n",
    "\n",
    "    .withColumnRenamed(\"genero\", 'sexo') \\\n",
    "    .drop('altura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaolimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando el Rey SELECT\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "deportistaOlimpicoDF = deportistaOlimpicoDF.select('deportista_id','r',\n",
    "                                                  col(\"edad\").alias(\"edadAljugador\"),\n",
    "                                                   \"equipo_id\"\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USANDO filter\n",
    "\n",
    "deportistaOlimpicoDF.sort(\"edadAljugador\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupaciones y operaciones join sobre DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaOlimpicoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "juegoDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportesOlimpicosDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paisesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOINS\n",
    "\n",
    "deportistaOlimpicoDF \\\n",
    "    .join(\n",
    "\n",
    "    resultadDF,\n",
    "    deportistaOlimpicoDF.deportista_id == resultadoDF.deportista_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    juegoDF,\n",
    "    juegoDF.juego_id == resultadoDF.juego_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    deportistaOlimpicoDF,\n",
    "    deportistaOlimpicoDF.evento_id == resultadoDF.evento_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .select(deportistaOlimpicoDF.nombre,           \n",
    "           \"edadAlJugar\",\n",
    "            \"medalla\",\n",
    "            col(\"anio\").alias(\"Anio de juego\"),\n",
    "            deportistaOlimpicoDF.nombre.alias(\"Nombre de disciplina\")\n",
    "           ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoDF \\\n",
    "    .join(\n",
    "    deportistaOlimpicoDF,\n",
    "    resultDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    \n",
    "    .join(\n",
    "    paisesDF,\n",
    "    deportistaOlimpicoDF.equipo_id == paisesDF.id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .select(\"medalla\",\n",
    "           paisesDF.equipo,\n",
    "            paisesDF.sigla\n",
    "    )\\\n",
    "\n",
    "    .where(resultadoDF.medalla != \"NA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion reto joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoDF.filter(resultadoDF.medalla != \"NA\") \\\n",
    "    .join(\n",
    "    deportistaOlimpicoDF,\n",
    "    resultDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    \n",
    "    .join(\n",
    "    paisesDF,\n",
    "    deportistaOlimpicoDF.equipo_id == paisesDF.id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .select(\"medalla\",\n",
    "           paisesDF.equipo,\n",
    "            paisesDF.sigla\n",
    "    )\\\n",
    "    .sport(col(\"sigla\").desc())\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones de agrupación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio = deportistaOlimpicoDF \\\n",
    "    .join(\n",
    "        resultadoDF,\n",
    "        deportistaOlimpicoDF.deportistaDF_id == resultadoDF.deportista_id,\n",
    "        \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    juegoDF,\n",
    "    juegoDF.juego_id == resultadoDF.juego_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    paisesDF,\n",
    "    deportistaOlimpicoDF.equipo_id == paisesDF.id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    deportistaOlimpicoDF,\n",
    "    resultDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .join(\n",
    "    deportesDF,\n",
    "    deportistaOlimpicoDF,\n",
    "    resultDF.deportista_id == deportistaOlimpicoDF.deportista_id,\n",
    "    \"left\"\n",
    "    )\\\n",
    "    .select(\n",
    "    \"sigla\",\n",
    "    \"anio\",\n",
    "    \"medalla\",\n",
    "    deportesolimpicosDF.nombre.alias(\"Nombre subdisciplina\"),\n",
    "    deportesDF.deporte.alias(\"Nombre disciplina\")\n",
    "    deportistaOlimpicoDf.nombre\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaSAnio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DESCARTAMOS DEPORTISTAS SIN MEDALLA\n",
    "\n",
    "medallistaXAnio2 = medallistaXAnio.filter(resultadoDF.medalla != \"NA\")\\\n",
    "    .sort(\"anio\")\\\n",
    "    .groupBy(\"sigla\", \"anio\", \"Nombre subdisciplina\") \\\n",
    "    .count()\n",
    "\n",
    "medallistaXAnio2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXANio2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio2.groupBy(\"Sigla\", \"anio\") \\\n",
    "    .agg(sum(\"count\").alias(\"Total de medallas\"), \\\n",
    "        avg(\"count\").alias(\"MEdallas promedio\")).show()\n",
    "\n",
    "# .agg() o agrevobe es la forma recomendada por la documentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGISTRO DE DATAFRAMES COMO TABLAS SQL\n",
    "\n",
    "resultadoDF.registerTempTable(\"resultado\")\n",
    "deportistaOlimpicoDF.registerTempTable(\"deportista\")\n",
    "paisesDF.registerTemTable(\"paises\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"SELECT * FROM deportista\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"\"\"\n",
    "    SELECT medalla, equipo, sigla FROM resultado as r\n",
    "    JOIN deportista as d\n",
    "    ON r.deportista_id = d.deportista_id\n",
    "    JOIN paises as p\n",
    "    ON p.id = d.equipo_id\n",
    "    WHERE medalla <> \"NA\"\n",
    "    ORDER BY sigla DESC\n",
    "    \"\"\").show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-84901cd22f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\r\n",
      "deportista2.csv  evento.csv\t      paises.csv\r\n",
      "deportista.csv\t juegos.csv\t      resultados.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deportista_id,nombre,genero,edad,altura,peso,equipo_id\r\n",
      "1,A Dijiang,1,24,180,80,199\r\n",
      "2,A Lamusi,1,23,170,60,199\r\n",
      "3,Gunnar Nielsen Aaby,1,24,,,273\r\n",
      "4,Edgar Lindenau Aabye,1,34,,,278\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 ./files/deportistaError.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DeportistaError_schema = StructType([\n",
    "    StructField(\"deportista_id\", StringType(), False),\n",
    "    StructField(\"nombre\", StringType(), False),\n",
    "    StructField(\"genero\", StringType(), False),\n",
    "    StructField(\"edad\", StringType(), False),\n",
    "    StructField(\"altura\", StringType(), False),\n",
    "    StructField(\"peso\", StringType(), False),\n",
    "    StructField(\"equipo_id\", StringType(), False)\n",
    "])\n",
    "\n",
    "deportistaErrorDF = sqlContext.read.format(\"csv\").\\\n",
    "    option(\"header\", True).\\\n",
    "    schema(DeportistaError_schema).\\\n",
    "    load(path+\"deportistaError.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deportistaErrorDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversionEnteros(valor):\n",
    "    try:\n",
    "        return int(valor) if len(valor) > o else 0\n",
    "    except tyError as e:\n",
    "        return 0\n",
    "    \n",
    "conversionEnteros_udf = udf(lambda z : conversionEnteros(z), IntegerType())\n",
    "sqlContext.udf.register(\"conversionEnteros_udf\", conversionEnteros_udf)\n",
    "\n",
    "DeportistaErrorDF.select(conversionEnteros_udf(\"altura\")\n",
    "    .alias(\"alturaUDF\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprendiendo la persistencia y particionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DF y Replicacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medallistaXAnio.is_cached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la persistencia\n",
    "medallistaXAnio.rdd.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saber el tiṕo de persistencia y nivel de replicacion\n",
    "\n",
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando la persistencia\n",
    "medallistaXAnio.rdd.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando persistencia MEMORY AND DISK con replicacion 2\n",
    "\n",
    "medallistaXAnio.rdd.persist(Storagelevel.MEMORY_AND_DISK_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saber el tipo de persistencia y nivel de recopilacion\n",
    "medallistaXAnio.rdd.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando la persistencia\n",
    "medallistaXAnio.rdd.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiendo un storageLevel custom\n",
    "StorageLevel.MEMORY_AND_DISK_# = Storagelevel(True, True, False, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persistimos el DATAFRAME\n",
    "medallistaXAnio.rdd.persist(StorageLevel.MEMORY_AND_DISK_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saber el tipo de persistencia y nivel de recopilacion\n",
    "\n",
    "medallistaXAnio.rdd..getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Particionando datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Particionado\") \\\n",
    "    .master(\"local[5]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.range(0,20)\n",
    "df.rdd.getnu,Partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redd1 = sparkContext.parallelize((0,20), 10)\n",
    "redd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArcivo = spark \\\n",
    "    .sparkContext \\\n",
    "    .textFile(\"./files/deportes.csv\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArchivo.getnu,partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArchivo.saveAsTextFile(\"./partition_example/salidadetexto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls \"./partition_example/salidadetexto/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos los archivos particionados\n",
    "\n",
    "!head -n 5 ./partition_example/salidadetexto/part-00004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.wholeTextFile('./partition_example/salidadetexto/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMA SENCILLA CARGAR\n",
    "lista = rdd.mapValues(lambda x: x.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1[0] for l in lista]\n",
    "lista.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = spark \\\n",
    "    .sparkContext \\\n",
    "    .textFile(','.join(lista), 10).map(lambda l: l.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
